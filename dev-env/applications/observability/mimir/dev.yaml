metaMonitoring:
  serviceMonitor:
    enabled: true
  grafanaAgent:
    enabled: true
    installOperator: true
    metrics:
      additionalRemoteWriteConfigs:
        - url: "http://mimir-nginx.observability.svc:80/api/v1/push"

distributor:
  replicas: 1
  resources:
    limits:
      memory: 1Gi
    requests:
      memory: 0.5Gi

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 512Mi


ingester:
  replicas: 1
  persistentVolume:
    size: 10Gi
  resources:
    requests:
      cpu: 100m
      memory: 512Mi

ruler:
  enabled: false
  replicas: 1

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 128Mi

querier:
  replicas: 1

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 128Mi

query_frontend:
  replicas: 1

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 128Mi

store_gateway:
  replicas: 1

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 512Mi

query_scheduler:
  replicas: 1

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 512Mi

compactor:
  replicas: 1
  persistentVolume:
    size: 5Gi

  resources:
    requests:
      cpu: 100m
      memory: 512Mi


# Configuration for nginx gateway
nginx:
  # -- Specifies whether nginx should be enabled
  enabled: true
  # -- Number of replicas for nginx
  replicas: 1
  # -- Enable logging of 2xx and 3xx HTTP requests
  verboseLogging: true
  autoscaling:
    # -- Enable autoscaling for nginx
    enabled: false
    # -- Minimum autoscaling replicas for nginx
    #minReplicas: 1
    # -- Maximum autoscaling replicas for nginx
    #maxReplicas: 3
    # -- Target CPU utilisation percentage for nginx
    #targetCPUUtilizationPercentage: 60
    # -- Target memory utilisation percentage for nginx
    #targetMemoryUtilizationPercentage:
  # -- See `kubectl explain deployment.spec.strategy` for more,
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  deploymentStrategy:
    type: RollingUpdate
  image:
    # -- The Docker registry for nginx image
    registry: docker.io
    # -- The nginx image repository
    repository: nginxinc/nginx-unprivileged
    # -- The nginx image tag
    tag: 1.19-alpine
    # -- The nginx image pull polic
    pullPolicy: IfNotPresent
  # -- The name of the PriorityClass for nginx pods
  priorityClassName: null
  # -- Labels for nginx pods
  podLabels: {}
  # -- Annotations for nginx pods
  podAnnotations: {}
  # -- Pod Disruption Budget
  podDisruptionBudget: {}
  # -- The SecurityContext for nginx containers
  podSecurityContext:
    fsGroup: 101
    runAsGroup: 101
    runAsNonRoot: true
    runAsUser: 101
  # -- The SecurityContext for nginx containers
  containerSecurityContext:
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
    allowPrivilegeEscalation: false
  # -- Resource requests and limits for the nginx
  resources: {}
  # -- Grace period to allow the nginx to shutdown before it is killed
  terminationGracePeriodSeconds: 30
  # -- Affinity for nginx pods. Passed through `tpl` and, thus, to be configured as string
  # @default -- Hard node and soft zone anti-affinity
  affinity: |
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: component
                  operator: In
                  values:
                    - nginx
            topologyKey: failure-domain.beta.kubernetes.io/zone

  annotations: {}

  # -- Node selector for nginx pods
  nodeSelector: {}
  # -- Tolerations for nginx pods
  tolerations: []
  # Nginx service configuration
  service:
    # -- Port of the nginx service
    port: 80
    # -- Type of the nginx service
    type: ClusterIP
    # -- ClusterIP of the nginx service
    clusterIP: null
    # -- Node port if service type is NodePort
    nodePort: null
    # -- Load balancer IPO address if service type is LoadBalancer
    loadBalancerIP: null
    # -- Annotations for the nginx service
    annotations: {}
    # -- Labels for nginx service
    labels: {}
  # Ingress configuration
  ingress:
    # -- Specifies whether an ingress for the nginx should be created
    enabled: true
    # -- Ingress Class Name. MAY be required for Kubernetes versions >= 1.18
    # ingressClassName: nginx
    # -- Annotations for the nginx ingress
    annotations: 
      nginx.ingress.kubernetes.io/rewrite-target: /
    hosts:
      - host: mimir.gamesmith.localhost
        paths:
          - path: /
            # -- pathType (e.g. ImplementationSpecific, Prefix, .. etc.) might also be required by some Ingress Controllers
            pathType: Prefix
    # -- TLS configuration for the nginx ingress
    #tls:
    #  - secretName: loki-nginx-tls
    #    hosts:
    #      - nginx.loki.example.com
  # Basic auth configuration
  basicAuth:
    # -- Enables basic authentication for nginx
    enabled: false
    # -- The basic auth username for nginx
    #username: null
    # -- The basic auth password for nginx
    #password: null
    # -- Uses the specified username and password to compute a htpasswd using Sprig's `htpasswd` function.
    # The value is templated using `tpl`. Override this to use a custom htpasswd, e.g. in case the default causes
    # high CPU load.
    #htpasswd: >-
    #  {{ htpasswd (required "'nginx.basicAuth.username' is required" .Values.nginx.basicAuth.username) (required "'nginx.basicAuth.password' is required" .Values.nginx.basicAuth.password) }}
    # -- Existing basic auth secret to use. Must contain '.htpasswd'
    #existingSecret: mimir-secret
  # Configures the readiness probe for nginx
  readinessProbe:
    httpGet:
      path: /
      port: http-metric
    initialDelaySeconds: 15
    timeoutSeconds: 1
  nginxConfig:
    # -- NGINX log format
    logFormat: |-
      main '$remote_addr - $remote_user [$time_local]  $status '
              '"$request" $body_bytes_sent "$http_referer" '
              '"$http_user_agent" "$http_x_forwarded_for"';
    # -- Allows appending custom configuration to the server block
    serverSnippet: ""
    # -- Allows appending custom configuration to the http block
    httpSnippet: ""
    # -- Config file contents for Nginx. Passed through the `tpl` function to allow templating
    # @default -- See values.yaml
    file: |
      worker_processes  5;  ## Default: 1
      error_log  /dev/stderr;
      pid        /tmp/nginx.pid;
      worker_rlimit_nofile 8192;

      events {
        worker_connections  4096;  ## Default: 1024
      }

      http {
        client_body_temp_path /tmp/client_temp;
        proxy_temp_path       /tmp/proxy_temp_path;
        fastcgi_temp_path     /tmp/fastcgi_temp;
        uwsgi_temp_path       /tmp/uwsgi_temp;
        scgi_temp_path        /tmp/scgi_temp;

        default_type application/octet-stream;
        log_format   {{ .Values.nginx.nginxConfig.logFormat }}

        {{- if .Values.nginx.verboseLogging }}
        access_log   /dev/stderr  main;
        {{- else }}

        map $status $loggable {
          ~^[23]  0;
          default 1;
        }
        access_log   /dev/stderr  main  if=$loggable;
        {{- end }}

        sendfile     on;
        tcp_nopush   on;
        resolver {{ .Values.global.dnsService }}.{{ .Values.global.dnsNamespace }}.svc.{{ .Values.global.clusterDomain }};

        {{- with .Values.nginx.nginxConfig.httpSnippet }}
        {{ . | nindent 2 }}
        {{- end }}

        server {
          listen 8080;

          {{- if .Values.nginx.basicAuth.enabled }}
          auth_basic           "Mimir";
          auth_basic_user_file /etc/nginx/secrets/.htpasswd;
          {{- end }}

          location = / {
            return 200 'OK';
            auth_basic off;
          }

          {{- if not (include "mimir.calculatedConfig" . | fromYaml).multitenancy_enabled }}
          proxy_set_header X-Scope-OrgID 0;
          {{- end }}

          # Distributor endpoints
          location /distributor {
            proxy_pass      http://{{ template "mimir.fullname" . }}-distributor.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /api/v1/push {
            proxy_pass      http://{{ template "mimir.fullname" . }}-distributor.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Alertmanager endpoints
          location {{ template "mimir.alertmanagerHttpPrefix" . }} {
            proxy_pass      http://{{ template "mimir.fullname" . }}-alertmanager.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /multitenant_alertmanager/status {
            proxy_pass      http://{{ template "mimir.fullname" . }}-alertmanager.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /api/v1/alerts {
            proxy_pass      http://{{ template "mimir.fullname" . }}-alertmanager.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Ruler endpoints
          location {{ template "mimir.prometheusHttpPrefix" . }}/config/v1/rules {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location {{ template "mimir.prometheusHttpPrefix" . }}/api/v1/rules {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          location /api/v1/rules {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location {{ template "mimir.prometheusHttpPrefix" . }}/api/v1/alerts {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location {{ template "mimir.prometheusHttpPrefix" . }}/rules {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /ruler/ring {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Rest of {{ template "mimir.prometheusHttpPrefix" . }} goes to the query frontend
          location {{ template "mimir.prometheusHttpPrefix" . }} {
            proxy_pass      http://{{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Buildinfo endpoint can go to any component
          location = /api/v1/status/buildinfo {
            proxy_pass      http://{{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          {{- with .Values.nginx.nginxConfig.serverSnippet }}
          {{ . | nindent 4 }}
          {{- end }}
        }
      }




# kubectl create -f /Users/sarah/src/agent/operations/agent-static-operator/crds/*

